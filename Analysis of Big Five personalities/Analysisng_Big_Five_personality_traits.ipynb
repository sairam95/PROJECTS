{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "kernelspec": {"display_name": "Python 3.5 (Experimental) with Spark 2.0", "name": "python3-spark20", "language": "python"}}, "nbformat_minor": 2, "cells": [{"outputs": [], "metadata": {}, "source": "import tweepy\nimport pandas as pd\nimport preprocessor as p\nfrom watson_developer_cloud import PersonalityInsightsV3\nfrom langdetect import detect_langs\nfrom langid.langid import LanguageIdentifier, model\nimport pandas as pd\nfrom pyspark import SparkContext\nfrom pyspark.sql import Row\nimport time\n#import pixiedust\nfrom pyspark import SparkContext\nimport itertools\nfrom pyspark.sql.functions import *", "cell_type": "code", "execution_count": 1}, {"outputs": [], "metadata": {}, "source": "#pixiedust.installPackage(\"https://github.com/sairam95/jar_file1/blob/master/spark-datasource-rest_2.11-2.1.0-SNAPSHOT.jar?raw=true\")\n#%pixiedustLog -l debug\n#pixiedust.installPackage(\"https://spark.bluemix.net/tenant/data/libs/spark-datasource-rest_2.11-2.1.0-SNAPSHOT.jar\")\n#pixiedust.installPackage(\"https://github.com/sairam95/jar_file1/blob/master/spark-datasource-rest_2.11-2.1.0-SNAPSHOT.jar?raw=True\")\n\n#pixiedust.printAllPackages()", "cell_type": "code", "execution_count": 2}, {"metadata": {}, "source": "### Reading data from the html table", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "actors = pd.read_html(\"https://www.socialbakers.com/statistics/twitter/profiles/india/celebrities/actor/page-1-2/\")[0]\nsports_star = pd.read_html(\"https://www.socialbakers.com/statistics/twitter/profiles/india/celebrities/sport-star/page-1-2/\")[0]\nwriter = pd.read_html(\"https://www.socialbakers.com/statistics/twitter/profiles/india/celebrities/writer/page-1-2/\")[0]\npoliticians = pd.read_html(\"https://www.socialbakers.com/statistics/twitter/profiles/india/society/politics/page-1-2/\")[0]", "cell_type": "code", "execution_count": 3}, {"metadata": {}, "source": "#### Renaming the columns in above data frames", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "data = [actors, sports_star, writer, politicians]\nfor item in data:\n    item.columns = ['rank', 'celebrity', 'followings', 'followers']", "cell_type": "code", "execution_count": 4}, {"metadata": {}, "source": "Merging all the categories of celebrities to one", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "df = pd.concat(data)\ncelebrities = df.celebrity.dropna(axis=0, how='all')", "cell_type": "code", "execution_count": 5}, {"outputs": [{"data": {"text/plain": "0    1  Amitabh Bachchan (@SrBachchan)\n1          2  Shah Rukh Khan (@iamsrk)\n2    3  Salman Khan (@BeingSalmanKhan)\n3       4  Akshay Kumar (@akshaykumar)\n4          5  Aamir Khan (@aamir_khan)\nName: celebrity, dtype: object"}, "metadata": {}, "output_type": "execute_result", "execution_count": 6}], "metadata": {}, "source": "celebrities.head()", "cell_type": "code", "execution_count": 6}, {"metadata": {}, "source": "#### cleaning the df columns to obtain Twitter user names", "cell_type": "markdown"}, {"outputs": [], "metadata": {"scrolled": true}, "source": "celeb_list  = celebrities.str.extract('@(\\S+)\\)', expand = True)[0].tolist()", "cell_type": "code", "execution_count": 7}, {"outputs": [], "metadata": {}, "source": "consumer_key = '2QTDFjrpIy71bwCuJXwgC85oD'\nconsumer_secret = '2sctC17IBpkigXU7TbzQnygSK3Uydit9yw4Pn0Xjhc5N8Jaftd'\naccess_token = '2891438354-ZrPa7xndtycr4DoNiG2JkdQXZ52WrZEIiIRyG3X'\naccess_secret = '92HfNTEzY9HNrbrHPcvYQPibFtA1BCtzRwPSiVTUETkhv'", "cell_type": "code", "execution_count": 8}, {"metadata": {}, "source": "### outputs only the Tweets of a specifc user", "cell_type": "markdown"}, {"metadata": {}, "source": "- following function uses LanguageIdentifier package for extracting the relevant tweets that have probability of being written in english greater than 0.9 \n- Language Detection using langid package gives better accuracy in detecting English language but compile time is high. \n", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "def detect_langid_relevant_tweets(screen_name):\n    #Twitter only allows access to a users most recent tweets with this method\n\n    #authorize twitter, initialize tweepy\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_secret)\n    api = tweepy.API(auth)\n\n    #initialize a list to hold all the tweepy Tweets\n    alltweets = []\n    relevant_tweet = []\n\n    #make initial request for most recent tweets (200 is the maximum allowed count)\n    new_tweets = api.user_timeline(screen_name = screen_name,count=200, lang='en', include_rts=False, exclude_replies = True)\n    content_type = 'text/plain'\n    content_language = None\n    accept ='application/json'\n    accept_language = None\n    raw_scores = False\n    consumption_preferences = False\n    csv_headers = False\n    \n    #save most recent tweets\n    \n    alltweets.extend(new_tweets)\n    #save the id of the oldest   less one\n    oldest = alltweets[-1].id - 1\n    \n    \n\n    #keep grabbing tweets until there are no tweets left to grab\n    while len(new_tweets) > 0:\n\n        #all subsiquent requests use the max_id param to prevent duplicates\n        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest, lang='en', include_rts=False, exclude_replies = True)\n\n        #save most recent tweets\n        alltweets.extend(new_tweets)\n\n        #update the id of the oldest tweet less one\n        oldest = alltweets[-1].id - 1\n    \n    for tweet in alltweets:\n        # Data Cleaning 2> Extracting alphabetic and space text from tweets \n        twt = \"\".join(x for x in p.clean(tweet.text) if x.isalpha() or x.isspace())\n        identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n        langProb = identifier.classify(twt)\n        if langProb[0] == 'en' and float(langProb[1]) > 0.9:\n            relevant_tweet.append(twt)\n    return relevant_tweet", "cell_type": "code", "execution_count": 234}, {"metadata": {}, "source": "### Extracting relevant tweets Using Lang detect package\n\n- Langdetect package has less compile time but accuracy of identifying English language is lesser.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "def detect_langs_relevant_tweets(screen_name):\n    #Twitter only allows access to a users most recent tweets with this method\n\n    #authorize twitter, initialize tweepy\n    start_time = time.time()\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_secret)\n    api = tweepy.API(auth)\n\n    #initialize a list to hold all the tweepy Tweets\n    alltweets = []\n    relevant_tweet = []\n\n    #make initial request for most recent tweets (200 is the maximum allowed count)\n    new_tweets = api.user_timeline(screen_name = screen_name,count=200, lang='en', include_rts=False, exclude_replies = True)\n    \n    #save most recent tweets\n    \n    alltweets.extend(new_tweets)\n    #save the id of the oldest tweet less one\n    oldest = alltweets[-1].id - 1\n    \n    #keep grabbing tweets until there are no tweets left to grab\n    while len(new_tweets) > 0:\n\n        #all subsiquent requests use the max_id param to prevent duplicates\n        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest, lang='en', include_rts=False, exclude_replies = True)\n\n        #save most recent tweets\n        alltweets.extend(new_tweets)\n\n        #update the id of the oldest tweet less one\n        oldest = alltweets[-1].id - 1\n    \n    for tweet in alltweets:\n        # Data Cleaning 2> Extracting alphabetic and space text from tweets \n        twt = \"\".join(x for x in p.clean(tweet.text) if x.isalpha() or x.isspace())\n        twt = twt.strip()\n        if (len(twt) > 0):\n            if (str(detect_langs(twt)[0])[:2] =='en') & (float(str(detect_langs(twt)[0])[3:]) > 0.9):\n                relevant_tweet.append(twt)\n    \n    return relevant_tweet", "cell_type": "code", "execution_count": 9}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "23.29035449028015\n89.24196600914001\n110.99212670326233\n113.45561408996582\n"}], "metadata": {}, "source": "exec_time =0\nfor celeb in celeb_list[0:4]:\n    start_time = time.time()\n    c =detect_langs_relevant_tweets(celeb)\n    exec_time = exec_time + (time.time()-start_time)\n    print(exec_time)\n    ", "cell_type": "code", "execution_count": 122}, {"outputs": [], "metadata": {}, "source": "## Get PI object using PI credentials - Aradhna\npersonality_insights = PersonalityInsightsV3(\nversion='2017-10-13',\nusername='04847f5d-afb4-4b08-8ed1-ae8ac7a56ac9',\npassword='8jniPKnFjDYO')", "cell_type": "code", "execution_count": 605}, {"outputs": [], "metadata": {}, "source": "# Ram PI Credentials \npersonality_insights = PersonalityInsightsV3(\nversion='2017-10-13',\nusername='f2264642-7379-488b-9154-e1373384cbc0',\npassword='rUBImsJrWStQ')", "cell_type": "code", "execution_count": 10}, {"outputs": [], "metadata": {}, "source": "## Call Personality Insights on the tweets for the user\ndef getPersonality(tweets):\n    # get tweets by user\n    start_time = time.time()\n    if tweets == None:\n        profile = None\n    else:\n        tweets_content = ' '.join(tweets)\n        # UTF-8 encoding\n        twt = tweets_content.encode('utf-8')\n        \n        # call PI to get personality profile\n        try:\n            profile = personality_insights.profile(twt, content_type = 'text/plain', content_language = None,\n                                           accept ='application/json', accept_language = None, raw_scores = False,\n                                           consumption_preferences = False, csv_headers = False)\n            \n        except Exception:\n            profile = None\n    print('Execution time for getPersonality function: ', time.time()-start_time)\n    return profile\n\n## Extract OCEAN percentiles from PI data\ndef extractOCEANtraits(profile):\n    start_time = time.time()\n    if profile == None:\n        openness = None\n        conscientiousness = None\n        extraversion = None\n        agreeableness = None\n        neuroticism = None\n    else:\n        personality = profile['personality']\n        openness = personality[0]['percentile']\n        conscientiousness = personality[1]['percentile']\n        extraversion = personality[2]['percentile']\n        agreeableness = personality[3]['percentile']\n        neuroticism = personality[4]['percentile']\n        \n    #print('Execution time for extractOCEANtraits function: ', time.time()-start_time)\n    return openness, conscientiousness, extraversion, agreeableness, neuroticism\n\n## Combine function calls for a user\ndef getPItraits(user):\n    \n    pitraits = {}\n    try:\n        ### Uncomment the line below to use FASTER language detection.\n        \n        #tweets = LanguageIdentifier_relevant_tweets(user)\n        \n        ### The line below gives a more ACCURATE language detection.\n        tweets = detect_langs_relevant_tweets(user)\n        # run PI profile on extracted tweets\n        profile = getPersonality(tweets)\n        # extract OCEAN traits\n        traits = extractOCEANtraits(profile)\n        if traits:\n            # writing the personality profile of a user into dictionary\n            OCEANTraits = dict(zip(['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism'],traits))\n            return dict([(user,OCEANTraits)])\n        else:\n            return None\n    except Exception:\n        return None", "cell_type": "code", "execution_count": 14}, {"metadata": {}, "source": "#### looping around the celebrities list and converting the Personality traits result dictionary into a data frame\n", "cell_type": "markdown"}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "Execution time for getPersonality function:  0.5358307361602783\nExecution time for getPersonality function:  0.5896203517913818\nExecution time for getPersonality function:  1.3133835792541504\nExecution time for getPersonality function:  1.3330190181732178\nExecution time for getPersonality function:  0.4638671875\nExecution time for getPersonality function:  0.47318029403686523\nExecution time for getPersonality function:  0.13445472717285156\nExecution time for getPersonality function:  0.13078761100769043\nExecution time for getPersonality function:  0.3430323600769043\nExecution time for getPersonality function:  0.5589053630828857\nTime without using Parallel processing:  261.263188123703\n"}], "metadata": {}, "source": "pitraits_dict = {}\n### Restricted the celeb list to 4 to display final output. \nstart = time.time()\nfor celeb in celeb_list[0:5]:\n    PItraits = getPItraits(celeb)\n    if PItraits is not None:\n        #print(celeb)\n        pitraits_dict.update(getPItraits(celeb))\n    else:\n        pass\ntraits_df = pd.DataFrame(pitraits_dict)\ntraits_df = traits_df.transpose()\ntraits_df\nprint('Time without using Parallel processing: ', (time.time() - start))", "cell_type": "code", "execution_count": 15}, {"metadata": {}, "source": "## Modified code for accessing Rest API service using pyspark", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "def tweet_cleaning(y):\n        # Data Cleaning 2> Extracting alphabetic and space text from tweets \n    twt = \"\".join(x for x in p.clean(y.text) if x.isalpha() or x.isspace())\n    twt = twt.strip()\n    if (len(twt) > 0):\n        if (str(detect_langs(twt)[0])[:2] =='en') & (float(str(detect_langs(twt)[0])[3:]) > 0.9):\n            return twt\n        else:\n            return \"\"\n    else:\n        return \"\"", "cell_type": "code", "execution_count": 608}, {"outputs": [], "metadata": {}, "source": "def detect_langs_relevant_tweets(screen_name):\n    #Twitter only allows access to a users most recent tweets with this method\n\n    #authorize twitter, initialize tweepy\n    start_time = time.time()\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_secret)\n    api = tweepy.API(auth)\n\n    alltweets = [] #initialize a list to hold all the tweepy Tweets\n\n    #make initial request for most recent tweets (200 is the maximum allowed count)\n    new_tweets = api.user_timeline(screen_name = screen_name,count=200, lang='en', include_rts=False, exclude_replies = True)  \n    alltweets.extend(new_tweets)  #save most recent tweets\n    oldest = alltweets[-1].id - 1 #save the id of the oldest tweet less one\n    \n    #keep grabbing tweets until there are no tweets left to grab\n    while len(new_tweets) > 0:\n\n        #all subsiquent requests use the max_id param to prevent duplicates\n        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest, lang='en', include_rts=False, exclude_replies = True)\n\n        alltweets.extend(new_tweets)  #save most recent tweets\n    \n        oldest = alltweets[-1].id - 1  #update the id of the oldest tweet less one\n    \n    #print(alltweets)\n    alltweets_rdd = sc.parallelize(alltweets)\n    relevant_tweet_rdd = alltweets_rdd.map(tweet_cleaning)\n        \n    #print('Execution time for relevant_tweets function: ', time.time()-start_time)\n    return relevant_tweet_rdd.collect()", "cell_type": "code", "execution_count": 609}, {"outputs": [], "metadata": {}, "source": "celeb_tweets_dict = {}\npitraits = {}", "cell_type": "code", "execution_count": 610}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "19.573287963867188\n68.83662867546082\n82.5223159790039\n84.33840417861938\n89.21816682815552\n"}], "metadata": {}, "source": "### Restricted the celeb list to 4 to display final output.\ncount, exec_time = 0, 0\nstart = time.time()\nfor celeb in celeb_list[0:5]:\n    count = count +1\n    start_time = time.time()\n    tweets= detect_langs_relevant_tweets(celeb)\n    #print('Count of celebrities whose tweets are extracted: ', count)\n    # get tweets by user\n    tweets_content = ' '.join(tweets)\n    exec_time = exec_time + (time.time()-start_time)\n    print(exec_time)\n    # UTF-8 encoding\n    #twt = tweets_content.encode('utf-8')    \n            # call PI to get personality profile\n    #print(twt)\n    \n    celeb_tweets_dict.update({celeb:tweets_content})", "cell_type": "code", "execution_count": 611}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "Twitter tweets extraction time for all celebrities:  89.21816682815552\n+---------------+------------------+------------------+-------------------+-------------------+-------------------+\n|      Celebrity|     agreeableness| conscientiousness|       extraversion|        neuroticism|           openness|\n+---------------+------------------+------------------+-------------------+-------------------+-------------------+\n|BeingSalmanKhan|0.6706261168601615|0.6809483726035818|0.15524348233633606| 0.5242585315880768| 0.3137146300929228|\n|    akshaykumar|0.9999967737036528|0.9990511244875682| 0.9934734571307775|  0.978818820923842| 0.8728125334468189|\n|         iamsrk|0.9843635833124369|0.7309454974693278| 0.5101603320672007| 0.5534924671151356|0.32683418096191347|\n|     SrBachchan|0.7568636452306099|0.9151003533179586|0.31380546597503944| 0.7574107558227448| 0.8114497631929141|\n|     aamir_khan|0.9553798951285026|0.8194044162955643| 0.5816580837189946|0.44617936260251917| 0.5373749483189343|\n+---------------+------------------+------------------+-------------------+-------------------+-------------------+\n\nTotal time for PI analysis:  5.418618679046631\n"}], "metadata": {"scrolled": true}, "source": "lst = celeb_tweets_dict.keys()\nceleb_dict = sc.parallelize(lst) #Creates an RDD of list of celebrites\n\n\n    #Key value pair of celebrity name and his Watson Insights\n\n    ##Code to the rest APi service\npi_time = time.time()\nceleb_pi = celeb_dict.map(lambda celeb:(celeb, personality_insights.profile(celeb_tweets_dict[celeb], content_type = 'text/plain', content_language = None,\n                                           accept ='application/json', accept_language = None, raw_scores = False,\n                                           consumption_preferences = False, csv_headers = False)))\n\n\n    ##code to extract the necessary part from the json format\n    #converting the pi insights into a dataframe\nOCEAN_Traits = celeb_pi.map(lambda x: Row(Celebrity = x[0], openness = x[1]['personality'][0]['percentile'], conscientiousness = x[1]['personality'][1]['percentile'], \n                                   extraversion = x[1]['personality'][2]['percentile'], agreeableness = x[1]['personality'][3]['percentile'],\n                                       neuroticism = x[1]['personality'][4]['percentile']))\n\n    ##Merging the data into a dataframe\ntype(OCEAN_Traits)\nOCEAN_Traits = sqlContext.createDataFrame(OCEAN_Traits)\n\n\nprint('Twitter tweets extraction time for all celebrities: ', exec_time)    \nOCEAN_Traits.show()\nprint('Total time for PI analysis: ', time.time()-pi_time)\n", "cell_type": "code", "execution_count": 612}, {"outputs": [], "metadata": {}, "source": "tweets = celeb_tweets_dict.values()", "cell_type": "code", "execution_count": 613}, {"outputs": [], "metadata": {}, "source": "#updating actors list\nactors = celeb_tweets_dict.keys()\nactors = list(itertools.chain.from_iterable(itertools.repeat(x, 5) for x in actors))\nactors_df = spark.createDataFrame(actors, schema=StringType())\nactors_df = actors_df.selectExpr(\"value as actor\")\n", "cell_type": "code", "execution_count": 669}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+\n|          actor|\n+---------------+\n|BeingSalmanKhan|\n|BeingSalmanKhan|\n|BeingSalmanKhan|\n|BeingSalmanKhan|\n|BeingSalmanKhan|\n|    akshaykumar|\n|    akshaykumar|\n|    akshaykumar|\n|    akshaykumar|\n|    akshaykumar|\n|         iamsrk|\n|         iamsrk|\n|         iamsrk|\n|         iamsrk|\n|         iamsrk|\n|     SrBachchan|\n|     SrBachchan|\n|     SrBachchan|\n|     SrBachchan|\n|     SrBachchan|\n+---------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "source": "actors_df.show()", "cell_type": "code", "execution_count": 670}, {"outputs": [], "metadata": {}, "source": "#newDF = pd.DataFrame.from_dict(celeb_tweets_dict, orient='index')", "cell_type": "code", "execution_count": 388}, {"outputs": [], "metadata": {}, "source": "#newDF.column = ['row']", "cell_type": "code", "execution_count": 393}, {"outputs": [{"data": {"text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th>row</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BeingSalmanKhan</th>\n      <td>A special thank you to and for the endless su...</td>\n    </tr>\n    <tr>\n      <th>akshaykumar</th>\n      <td>Hi guys extremely sorry about the delay will b...</td>\n    </tr>\n    <tr>\n      <th>iamsrk</th>\n      <td>My friend A man A parent  This Sunday at pm on...</td>\n    </tr>\n    <tr>\n      <th>SrBachchan</th>\n      <td>T  At the venue rehearsing for tomorrow event ...</td>\n    </tr>\n    <tr>\n      <th>aamir_khan</th>\n      <td>Hey guys watch the video and do the best you ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                 0\nrow                                                               \nBeingSalmanKhan   A special thank you to and for the endless su...\nakshaykumar      Hi guys extremely sorry about the delay will b...\niamsrk           My friend A man A parent  This Sunday at pm on...\nSrBachchan       T  At the venue rehearsing for tomorrow event ...\naamir_khan        Hey guys watch the video and do the best you ..."}, "metadata": {}, "output_type": "execute_result", "execution_count": 394}], "metadata": {}, "source": "#newDF", "cell_type": "code", "execution_count": 394}, {"outputs": [], "metadata": {}, "source": "#newDF = pd.DataFrame(newDF.row.str.split(' ',1).tolist(),columns = ['celebrity','value'])", "cell_type": "code", "execution_count": 396}, {"outputs": [], "metadata": {}, "source": "tweet_rdd = sc.parallelize(tweets)", "cell_type": "code", "execution_count": 671}, {"outputs": [{"data": {"text/plain": "5"}, "metadata": {}, "output_type": "execute_result", "execution_count": 672}], "metadata": {}, "source": "tweet_rdd.count()", "cell_type": "code", "execution_count": 672}, {"outputs": [], "metadata": {}, "source": "from pyspark.sql.types import StringType\nwatsoninputDf = tweet_rdd.toDF(StringType())", "cell_type": "code", "execution_count": 673}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|               value|\n+--------------------+\n| A special thank ...|\n|Hi guys extremely...|\n|My friend A man A...|\n|T  At the venue r...|\n| Hey guys watch t...|\n+--------------------+\n\n"}], "metadata": {}, "source": "watsoninputDf.show()", "cell_type": "code", "execution_count": 674}, {"outputs": [], "metadata": {}, "source": "watsoninputDf.createOrReplaceTempView(\"watsoninputt\")", "cell_type": "code", "execution_count": 675}, {"outputs": [], "metadata": {}, "source": "watsonuri = 'https://gateway.watsonplatform.net/personality-insights/api/v2/profile'", "cell_type": "code", "execution_count": 676}, {"outputs": [], "metadata": {}, "source": "# Now we create the parameter map to pass to the REST Data Source.\nprmsWatson = { 'url' : watsonuri, 'input' : 'watsoninputt', 'inputContentType' :'text/plain', 'inputFormat' : 'text', 'userId' : 'f2264642-7379-488b-9154-e1373384cbc0','userPassword' : 'rUBImsJrWStQ', 'readTimeout' : '10000', 'connectionTimeout' : '2000', 'partitions' : '2'}", "cell_type": "code", "execution_count": 677}, {"outputs": [], "metadata": {}, "source": "watsonDf = spark.read.format(\"org.apache.dsext.spark.datasource.rest.RestDataSource\").options(**prmsWatson).load()", "cell_type": "code", "execution_count": 678}, {"outputs": [], "metadata": {}, "source": "watsonDf.cache()", "cell_type": "code", "execution_count": null}, {"outputs": [], "metadata": {}, "source": "watsonDf.count()", "cell_type": "code", "execution_count": null}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- output: struct (nullable = true)\n |    |-- id: string (nullable = true)\n |    |-- processed_lang: string (nullable = true)\n |    |-- source: string (nullable = true)\n |    |-- tree: struct (nullable = true)\n |    |    |-- children: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- children: array (nullable = true)\n |    |    |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |    |    |-- category: string (nullable = true)\n |    |    |    |    |    |    |-- children: array (nullable = true)\n |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |    |    |    |    |-- category: string (nullable = true)\n |    |    |    |    |    |    |    |    |-- children: array (nullable = true)\n |    |    |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |    |    |    |    |    |    |-- category: string (nullable = true)\n |    |    |    |    |    |    |    |    |    |    |-- id: string (nullable = true)\n |    |    |    |    |    |    |    |    |    |    |-- name: string (nullable = true)\n |    |    |    |    |    |    |    |    |    |    |-- percentage: double (nullable = true)\n |    |    |    |    |    |    |    |    |    |    |-- sampling_error: double (nullable = true)\n |    |    |    |    |    |    |    |    |-- id: string (nullable = true)\n |    |    |    |    |    |    |    |    |-- name: string (nullable = true)\n |    |    |    |    |    |    |    |    |-- percentage: double (nullable = true)\n |    |    |    |    |    |    |    |    |-- sampling_error: double (nullable = true)\n |    |    |    |    |    |    |-- id: string (nullable = true)\n |    |    |    |    |    |    |-- name: string (nullable = true)\n |    |    |    |    |    |    |-- percentage: double (nullable = true)\n |    |    |    |    |-- id: string (nullable = true)\n |    |    |    |    |-- name: string (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |    |-- warnings: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- message: string (nullable = true)\n |    |    |    |-- warning_id: string (nullable = true)\n |    |-- word_count: long (nullable = true)\n |    |-- word_count_message: string (nullable = true)\n |-- value: string (nullable = true)\n\n"}], "metadata": {}, "source": "watsonDf.printSchema()", "cell_type": "code", "execution_count": 679}, {"outputs": [], "metadata": {}, "source": "watsonDf.createOrReplaceTempView(\"watsonresulttbl\")", "cell_type": "code", "execution_count": 680}, {"outputs": [], "metadata": {}, "source": "watsonPersonalityDf.createOrReplaceTempView(\"watsonPersonalitytbl\")", "cell_type": "code", "execution_count": 681}, {"outputs": [], "metadata": {}, "source": "watsonPersonality2Df = spark.sql(\"select value, inline(children) from watsonPersonalitytbl\")", "cell_type": "code", "execution_count": 682}, {"outputs": [], "metadata": {}, "source": "watsonPersonality2Df.createOrReplaceTempView(\"watsonPersonality2tbl\")", "cell_type": "code", "execution_count": 683}, {"outputs": [], "metadata": {}, "source": "watsonPersonality3Df = spark.sql(\"select value, inline(children) from watsonPersonality2tbl where category='personality' \")", "cell_type": "code", "execution_count": 684}, {"outputs": [], "metadata": {}, "source": "watsonPersonality3Df.createOrReplaceTempView(\"watsonPersonality3tbl\")", "cell_type": "code", "execution_count": 685}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------------+-------------------+\n|               value|             name|         percentage|\n+--------------------+-----------------+-------------------+\n| A special thank ...|         Openness|0.31232384272828007|\n| A special thank ...|Conscientiousness| 0.6870956327675607|\n| A special thank ...|     Extraversion| 0.1462037421505351|\n| A special thank ...|    Agreeableness| 0.6768484959942631|\n| A special thank ...|  Emotional range| 0.5252973624289085|\n|My friend A man A...|         Openness|0.33259758545955875|\n|My friend A man A...|Conscientiousness| 0.7193596833200233|\n|My friend A man A...|     Extraversion| 0.5050132104141529|\n|My friend A man A...|    Agreeableness| 0.9819873802730845|\n|My friend A man A...|  Emotional range| 0.5408504292541368|\n| Hey guys watch t...|         Openness| 0.5328151749030463|\n| Hey guys watch t...|Conscientiousness| 0.8206585028356688|\n| Hey guys watch t...|     Extraversion| 0.5741938561631901|\n| Hey guys watch t...|    Agreeableness| 0.9563494138573354|\n| Hey guys watch t...|  Emotional range| 0.4431156910544323|\n|T  At the venue r...|         Openness| 0.8150558232245735|\n|T  At the venue r...|Conscientiousness| 0.9160682009778915|\n|T  At the venue r...|     Extraversion|  0.316679897539034|\n|T  At the venue r...|    Agreeableness| 0.7644182943461479|\n|T  At the venue r...|  Emotional range| 0.7541127627403503|\n+--------------------+-----------------+-------------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "source": "spark.sql(\"select value,name,percentage from watsonPersonality3tbl\").show()", "cell_type": "code", "execution_count": 686}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+\n|               value|   category|            children|               id|             name|         percentage|      sampling_error|\n+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+\n| A special thank ...|personality|[[personality,Adv...|         Openness|         Openness|0.31232384272828007|        0.0508007798|\n| A special thank ...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.6870956327675607|       0.06470402876|\n| A special thank ...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.1462037421505351|       0.04871731644|\n| A special thank ...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.6768484959942631|        0.0859550166|\n| A special thank ...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.5252973624289085|       0.07829400568|\n|My friend A man A...|personality|[[personality,Adv...|         Openness|         Openness|0.33259758545955875|0.042992817759999996|\n|My friend A man A...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.7193596833200233|       0.05494143976|\n|My friend A man A...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.5050132104141529|       0.04127840956|\n|My friend A man A...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9819873802730845|        0.0768578406|\n|My friend A man A...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.5408504292541368|        0.0741968902|\n| Hey guys watch t...|personality|[[personality,Adv...|         Openness|         Openness| 0.5328151749030463|       0.05244042064|\n| Hey guys watch t...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.8206585028356688|       0.06750567816|\n| Hey guys watch t...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.5741938561631901|       0.05009963608|\n| Hey guys watch t...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9563494138573354|       0.08771762104|\n| Hey guys watch t...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.4431156910544323| 0.07947702631999999|\n|Hi guys extremely...|personality|[[personality,Adv...|         Openness|         Openness| 0.8510684621344495|        0.0632449333|\n|Hi guys extremely...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.9989964488083662|        0.0794396802|\n|Hi guys extremely...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.9925143353169668|        0.0593038003|\n|Hi guys extremely...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9999961838651272|         0.100354973|\n|Hi guys extremely...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.9778249335629177|         0.094732555|\n+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "source": "watsonPersonality3Df.show()", "cell_type": "code", "execution_count": 687}, {"outputs": [], "metadata": {}, "source": "actors_df.createOrReplaceTempView(\"actorstbl\")", "cell_type": "code", "execution_count": 688}, {"outputs": [], "metadata": {}, "source": "df = spark.sql(\"WITH CTE1 AS \\\n( \\\n    SELECT ROW_NUMBER() OVER(ORDER BY value) AS ROWNUM, * FROM watsonPersonality3tbl \\\n), \\\nCTE2 AS \\\n( \\\n    SELECT ROW_NUMBER() OVER (ORDER BY actor) AS ROWNUM, * FROM actorstbl \\\n) \\\nSELECT * \\\nFROM CTE1 FULL JOIN CTE2 ON CTE1.ROWNUM = CTE2.ROWNUM\")", "cell_type": "code", "execution_count": 689}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+------+---------------+\n|ROWNUM|               value|   category|            children|               id|             name|         percentage|      sampling_error|ROWNUM|          actor|\n+------+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+------+---------------+\n|     1| A special thank ...|personality|[[personality,Adv...|         Openness|         Openness|0.31232384272828007|        0.0508007798|     1|BeingSalmanKhan|\n|     2| A special thank ...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.6870956327675607|       0.06470402876|     2|BeingSalmanKhan|\n|     3| A special thank ...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.1462037421505351|       0.04871731644|     3|BeingSalmanKhan|\n|     4| A special thank ...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.6768484959942631|        0.0859550166|     4|BeingSalmanKhan|\n|     5| A special thank ...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.5252973624289085|       0.07829400568|     5|BeingSalmanKhan|\n|     6| Hey guys watch t...|personality|[[personality,Adv...|         Openness|         Openness| 0.5328151749030463|       0.05244042064|     6|     SrBachchan|\n|     7| Hey guys watch t...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.8206585028356688|       0.06750567816|     7|     SrBachchan|\n|     8| Hey guys watch t...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.5741938561631901|       0.05009963608|     8|     SrBachchan|\n|     9| Hey guys watch t...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9563494138573354|       0.08771762104|     9|     SrBachchan|\n|    10| Hey guys watch t...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.4431156910544323| 0.07947702631999999|    10|     SrBachchan|\n|    11|Hi guys extremely...|personality|[[personality,Adv...|         Openness|         Openness| 0.8510684621344495|        0.0632449333|    11|     aamir_khan|\n|    12|Hi guys extremely...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.9989964488083662|        0.0794396802|    12|     aamir_khan|\n|    13|Hi guys extremely...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.9925143353169668|        0.0593038003|    13|     aamir_khan|\n|    14|Hi guys extremely...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9999961838651272|         0.100354973|    14|     aamir_khan|\n|    15|Hi guys extremely...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.9778249335629177|         0.094732555|    15|     aamir_khan|\n|    16|My friend A man A...|personality|[[personality,Adv...|         Openness|         Openness|0.33259758545955875|0.042992817759999996|    16|    akshaykumar|\n|    17|My friend A man A...|personality|[[personality,Ach...|Conscientiousness|Conscientiousness| 0.7193596833200233|       0.05494143976|    17|    akshaykumar|\n|    18|My friend A man A...|personality|[[personality,Act...|     Extraversion|     Extraversion| 0.5050132104141529|       0.04127840956|    18|    akshaykumar|\n|    19|My friend A man A...|personality|[[personality,Alt...|    Agreeableness|    Agreeableness| 0.9819873802730845|        0.0768578406|    19|    akshaykumar|\n|    20|My friend A man A...|personality|[[personality,Ang...|      Neuroticism|  Emotional range| 0.5408504292541368|        0.0741968902|    20|    akshaykumar|\n+------+--------------------+-----------+--------------------+-----------------+-----------------+-------------------+--------------------+------+---------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "source": "df.show()", "cell_type": "code", "execution_count": 690}, {"outputs": [], "metadata": {}, "source": "reshaped_df = df.groupby('actor').pivot('id').max('percentage')", "cell_type": "code", "execution_count": 692}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+------------------+------------------+------------------+------------------+-------------------+\n|          actor|     Agreeableness| Conscientiousness|      Extraversion|       Neuroticism|           Openness|\n+---------------+------------------+------------------+------------------+------------------+-------------------+\n|    akshaykumar|0.9819873802730845|0.7193596833200233|0.5050132104141529|0.5408504292541368|0.33259758545955875|\n|         iamsrk|0.7644182943461479|0.9160682009778915| 0.316679897539034|0.7541127627403503| 0.8150558232245735|\n|     SrBachchan|0.9563494138573354|0.8206585028356688|0.5741938561631901|0.4431156910544323| 0.5328151749030463|\n|BeingSalmanKhan|0.6768484959942631|0.6870956327675607|0.1462037421505351|0.5252973624289085|0.31232384272828007|\n|     aamir_khan|0.9999961838651272|0.9989964488083662|0.9925143353169668|0.9778249335629177| 0.8510684621344495|\n+---------------+------------------+------------------+------------------+------------------+-------------------+\n\n"}], "metadata": {}, "source": "reshaped_df.show()", "cell_type": "code", "execution_count": 693}, {"outputs": [], "metadata": {}, "source": "", "cell_type": "code", "execution_count": null}], "nbformat": 4}